# Bibliography
Bitton, Adrien, Philippe Esling, and Tatsuya Harada. ‘Neural Granular Sound Synthesis’. arXiv, 3 July 2021. [http://arxiv.org/abs/2008.01393](http://arxiv.org/abs/2008.01393).

Caillon, Antoine. ‘RAVE.Js’. Accessed 16 January 2023. [https://caillonantoine.github.io/ravejs/](https://caillonantoine.github.io/ravejs/).

Caillon, Antoine, and Axel Chemla-Romeu-Santos. ‘Nn~’. ACIDS Ircam. Accessed 16 January 2023. [https://github.com/acids-ircam/nn_tilde](https://github.com/acids-ircam/nn_tilde).

Caillon, Antoine, and Philippe Esling. ‘RAVE: A Variational Autoencoder for Fast and High-Quality Neural Audio Synthesis’. arXiv, 15 December 2021. [http://arxiv.org/abs/2111.05011](http://arxiv.org/abs/2111.05011).

Chollet, François. _Deep Learning with Python_. Second edition. Shelter Island: Manning Publications, 2021.

Collins, Lyn. _Think (About It)_. LP. Monarch Pressing, 1972. [https://www.discogs.com/master/52645-Lyn-Collins-Think-About-It](https://www.discogs.com/master/52645-Lyn-Collins-Think-About-It).

Dhariwal, Prafulla, Heewoo Jun, Christine Payne, Jong Wook Kim, Alec Radford, and Ilya Sutskever. ‘Jukebox: A Generative Model for Music’. arXiv, 30 April 2020. [http://arxiv.org/abs/2005.00341](http://arxiv.org/abs/2005.00341).

McFee, Brian, Alexandros Metsai, Matt McVicar, Stefan Balke, Carl Thomé, Colin Raffel, Frank Zalkow, et al. ‘Librosa/Librosa: 0.9.2’. Zenodo, 27 June 2022. [https://doi.org/10.5281/ZENODO.6759664](https://doi.org/10.5281/ZENODO.6759664).

McLeavey Payne, Christine. ‘MuseNet’. _OpenAI Blog_ (blog), n.d. [https://openai.com/blog/musenet/](https://openai.com/blog/musenet/).

‘MuBu’. Ircam. Accessed 22 January 2023. [https://forum.ircam.fr/projects/detail/mubu/](https://forum.ircam.fr/projects/detail/mubu/).

Oord, Aaron van den, Sander Dieleman, Heiga Zen, Karen Simonyan, Oriol Vinyals, Alex Graves, Nal Kalchbrenner, Andrew Senior, and Koray Kavukcuoglu. ‘WaveNet: A Generative Model for Raw Audio’. arXiv, 19 September 2016. [http://arxiv.org/abs/1609.03499](http://arxiv.org/abs/1609.03499).

OpenAI. ‘ChatGPT: Optimizing Language Models for Dialogue’. Accessed 16 January 2023. [https://openai.com/blog/chatgpt/](https://openai.com/blog/chatgpt/).

Pasini, Marco, and Jan Schlüter. ‘Musika! Fast Infinite Waveform Music Generation’. arXiv, 18 August 2022. [http://arxiv.org/abs/2208.08706](http://arxiv.org/abs/2208.08706).

Roads, Curtis. _Microsound_. 1. paperback ed. Cambridge, Mass.: MIT Press, 2004.

Schwarz, D. ‘Corpus-Based Concatenative Synthesis’. _IEEE Signal Processing Magazine_ 24, no. 2 (March 2007): 92–104. [https://doi.org/10.1109/MSP.2007.323274](https://doi.org/10.1109/MSP.2007.323274).

Schwarz, Diemo. ‘CataRT’. Ircam. Accessed 30 January 2023. [http://catart.concatenative.net/](http://catart.concatenative.net/).

Schwarz, Diemo, Sylvain Cadars, and Norbert Schnell. ‘What Next? Continuation in Real-Time Corpus-Based Concatenative Synthesis’. In _International Computer Music Conference (ICMC)_, 1–1. Belfast, United Kingdom, 2008. [https://hal.archives-ouvertes.fr/hal-01161402](https://hal.archives-ouvertes.fr/hal-01161402).

Steinmetz, Christian J., and Joshua D. Reiss. ‘Auraloss: Audio-Focused Loss Functions in PyTorch’. Centre for Digital Music, Queen Mary University of London, 15 December 2020. [auraloss: Audio-focused loss functions in PyTorch](https://doi.org/auraloss: Audio-focused loss functions in PyTorch).

‘TorchScript’. The Linux Foundation. Accessed 22 January 2023. [https://pytorch.org/docs/stable/jit.html](https://pytorch.org/docs/stable/jit.html).

Tremblay, Pierre Alexandre, Gerard Roma, and Owen Green. ‘Enabling Programmatic Data Mining as Musicking: The Fluid Corpus Manipulation Toolkit’. _Computer Music Journal_ 45, no. 2 (1 June 2021): 9–23. [https://doi.org/10.1162/comj_a_00600](https://doi.org/10.1162/comj_a_00600).